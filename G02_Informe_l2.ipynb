{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Nfaun0M1Es"
      },
      "source": [
        "# Entrega - Tarea 2\n",
        "\n",
        "### Grupo 2:\n",
        "     - Darío Rosa 3813883-9\n",
        "     - Diego Aleman 4952936-0\n",
        "     - Gabriel Kryger 4933558-9\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoqSjFWaM1E4"
      },
      "source": [
        "## 1. Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ia5iqHJM1E7"
      },
      "source": [
        "El objetivo de esta tarea es construir un clasificador utilizando el Algoritmo ID3 en su variante que permite el manejo de atributos continuos.\n",
        "Para medir el éxito del aprendizaje vamos a utilizar las medidas accuracy, precision, recall y medida F1, utilizando para su cálculo la librería sklearn. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFf5fEToM1E8"
      },
      "source": [
        "## 2. Diseño"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtPsdk3bSQVp"
      },
      "source": [
        "### 2.1 Preprocesamiento de datos\n",
        "Al inicio es necesario pre procesar los datos que fueron entregados en el laboratorio, para que cumplan con algunas condiciones que nos faciliten su procesamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Jo0tgmO9je"
      },
      "source": [
        "### 2.1.1 Tratamiento de los valores textuales\n",
        "Haciendo un análisis de los atributos contenidos es el DataSet, vimos que no tenemos atributos textuales de texto libre, solo valores textuales que representan valores discretos. \n",
        "Para la ejecución de nuestro algoritmo se necesitó asociar todos los valores textuales a valores reales. Esto se hizo tomando todos los valores posibles (sin contar indefinidos o equivalentes) y, a cada valor textual asociándoles un valor natural de forma incremental. Para este contexto creemos que no es necesario la aplicación de algoritmos como el de OneHotEncoding porque nuestro algoritmo no va a hacer ninguna operación sobre estos reales, solo los va a tratar como números discretos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZvL7jJGRZCx"
      },
      "source": [
        "### 2.1.2 Tratamiento de valores reales, discretización\n",
        "En el caso de valores reales continuos, se busca discretizar los valores reales. En nuestro caso no vamos a realizar este tratamiento en el pre-procesamiento sino que dentro del algoritmo mismo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbR2I0N-TKJe"
      },
      "source": [
        "### 2.1.2 Tratamiento de valores reales, discretización\n",
        "En el caso de valores reales continuos, se busca discretizar los valores reales. En nuestro caso no vamos a realizar este tratamiento en el preprocesamiento sino que dentro del algoritmo mismo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwajseAuQZq4"
      },
      "source": [
        "### 2.1.4 Tratamiento de valores faltantes\n",
        "En el caso de que hubiera valores faltantes en una fila, se tomó la decisión de, en caso de que el valor sea real, asociarle a esta celda el valor promedio de la columna. \n",
        "\n",
        "Nuestro algoritmo no contempla que hacer, en caso de que haya celdas faltantes en una columna textual, se toma el desconocimiento como un posible valor.\n",
        "Para el caso de las columnas textuales, encontramos que solamente la columna \"smoking_status\" toma celdas faltantes con el valor \"Unknown\". Tomamos la decisión de no suplirlos con ningún tipo de técnica (ya sea tomando el valor más común o asignando un valor según la probabilidad del resto) y utilizar el valor \"Unknown\" como un valor válido. Esta decisión fue tomada, ya que la cantidad de valores \"Unknown\" es muy elevada y al suplir este valor con otro, es seguro que esto genere tuplas con ejemplos erróneos que lleven a que el árbol aprenda a clasificar correctamente los mismos, que lo inducen a clasificar erróneamente ejemplos del dominio.\n",
        "\n",
        "Cabe destacar que este reemplazo de datos faltantes es implementado luego de la separación de los conjuntos de entrenamiento y evaluación y solo en el conjunto de entrenamiento, así no afectar la realidad al momento de evaluar el algoritmo. A diferencia del algoritmo sklearn, nuestro clasificador permite la evaluación con atributos faltantes, simplemente retornaremos el valor más común de \"stroke\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEDxEYc_Sxsi"
      },
      "source": [
        "### 2.1.5 Tratamiento del desbalance en el muestreo\n",
        "El algoritmo que se pidió implementar deberá de tener como resultado la probabilidad de tener una condición, en nuestro caso la probabilidad de haber tenido un infarto, por lo tanto, para evitar un bias en las respuestas del algoritmo es necesario equiparar la cantidad de resultados positivos y negativos en nuestros datos de entrenamiento. \n",
        "El conjunto enviado se encuentra muy desbalanceado, teniendo muchos casos negativos y muy pocos positivos, esto va a afectar mucho el resultado y el entrenamiento de nuestro clasificador. Para el balanceo de estos datos vamos a usar Oversample y así obtener una muestra más distribuida de casos positivos y negativos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ON-2Dqpocn"
      },
      "source": [
        "### 2.1.6 Tratamiento de los valores fuera de la realidad\n",
        "\n",
        "En caso de que en el que los datos haya columnas las cuales no sean relevantes en la realidad observada, por ejemplo en nuestro caso el ID, no se tomaran en cuenta a la hora de realizar el algoritmo, ya que esto podría llevar a un sobre ajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds0j_PqaS3G1"
      },
      "source": [
        "### 2.1.7 División de conjuntos\n",
        "Hicimos la separación de conjuntos en conjunto de entrenamiento y conjunto de validación en un 80% - 20%, ya que es la proporción recomendada. No hicimos separación de conjunto de test, ya que creemos que el objetivo de este laboratorio es la de realizar muchas evaluaciones y aprovechar toda la cantidad posible de ejemplos para el entrenamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fRX080oShOy"
      },
      "source": [
        "## 2.2 Algoritmo\n",
        "Para la creación del clasificador y como fue solicitado en la letra del laboratorio, fue implementado el árbol de decisión utilizando el algoritmo ID3 dado en el teórico, con la variante de atributos continuos. Pero antes de continuar con su implementación vamos a detallar otras funcionalidades que fueron necesarias.\n",
        "\n",
        "### 2.2.1 Información de atributos\n",
        "Fue implementada una función llamada \"GetFullColumnDescriptor\" que retorna un diccionario con información necesaria para el algoritmo ID3, entre ellas:\n",
        "- Nombre del Atributo\n",
        "- Si su valor es real, continuo o discreto (discreto = true)\n",
        "- Listado con sus valores posibles (basándonos en el conjunto de datos)\n",
        "\n",
        "En el caso de atributos con valores continuos, en la lista de posibles valores, retornamos un solo valor que es el seleccionado como división de los valores en dos intervalos. (la selección de este valor, será explicado más adelante)\n",
        "\n",
        "### 2.2.2 Cálculo de Ganancia\n",
        "En el árbol generado por el algoritmo ID3, tiene un gran impacto en el performance la buena selección del atributo en cada paso de la recursión, para esta elección calculamos la \"ganancia\":\n",
        "\n",
        "$$\n",
        "Ganancia(S,A) = 1 - \\sum \\limits _{v \\in Val(A)} \\frac{|Sv|}{|S|}.Entropía(sv)\n",
        "$$\n",
        "\n",
        "Donde \n",
        "- Entropía(sv): Es la entropía teniendo en cuenta solo los ejemplos con el valor $v{_i}$ en el atributo $A$\n",
        "\n",
        "### 2.2.3 Selección del \"mejor\" atributo en el paso recursivo\n",
        "\n",
        "En nuestra solución, esta selección de atributos fue implementada en la función\n",
        "\"GetBestAtt\" que recibe un DataFrame con los datos y la información de todos los atributos, retornando el mejor atributo para la recursión, que en nuestro caso será aquel con mayor ganancia.\n",
        "La función \"GetAttGanancia\" calcula dicha ganancia teniendo en cuenta si el atributo es continuo o discreto.\n",
        "\n",
        "**Atributos Discretos:** Para el cálculo de la ganancia para un atributo, simplemente calculamos su ganancia utilizando la fórmula presentada anteriormente y obteniendo los posibles valores de la función \"GetFullColumnDescriptor\".\n",
        "\n",
        "**Atributos Continuos:** En el caso de atributos con valores continuos, vamos a usar el valor seleccionado en la función \"GetFullColumnDescriptor\" donde es seleccionado un valor Real que es el que particióna el rango de valores del atributo en dos intervalos que maximizan su ganancia. Para obtener este valor seguimos los siguientes pasos:\n",
        "\n",
        "- Ordenamos los datos en forma ascendente por el atributo a estudio. (DataFrame original, ya que se implementa en la función \"GetFullColumnDescriptor\")\n",
        "- Analizamos los valores del atributo, donde el atributo Stroke cambia de valor.\n",
        "- Para estos valores calculamos la ganancia de dicha partición teniendo en cuenta la siguiente fórmula:\n",
        " \n",
        " $$\n",
        "    Ganancia(v{_i}) = 1 - Ganancia(V(S)<=v{_i}) - Ganancia(V(S)>v{_i})\n",
        " $$\n",
        "\n",
        "Por lo tanto, al en cada paso de la recursión el algoritmo va a seleccionar el atributo que tiene mayor Ganancia.\n",
        "\n",
        "### 2.2.4 Descripción general del algoritmo\n",
        "Nuestra solución tuvimos que modificar algunas sentencias del algoritmo básico dado en el teórico. El árbol de decisión es credo en la función \"ID3_DecisionTree\", que recibe como parámetro el DataFrame de entrenamiento y el tamaño máximo de profundidad del árbol.\n",
        "A continuación un pseudocódigo de nuestro algoritmo: \n",
        "\n",
        "1. Analizamos los retono de los casos base\n",
        "  - Si el parámetro maxlevels es cero, significa que llegamos al máximo de niveles permitidos. En este caso retornamos una hoja (tipo G02TreeSheet) con la moda del atributo \"stroke\" como resultado.\n",
        "  - Si todos los ejemplos tienen el mismo valor en el atributo \"stroke\", retornamos una hoja con el valor de \"stroke\" .\n",
        "  - Si el conjunto de ejemplos recibidos por parámetro tiene solo la columna \"stroke\", retornamos la moda de ese atributo. \n",
        "\n",
        "2. Seleccionamos el mejor atributo (idColumn)\n",
        "3. Creo un objeto de la clase \"G02Tree\" que usaremos como retorno\n",
        "4. Analizamos si el atributo es discreto:\n",
        "\n",
        "  4.1 Por cada valor permitido, Obtengo el conjunto de ejemplos con ese valor y ejecutamos el llamado recursivo a la función con los ejemplos y maxLevels-1.\n",
        "  4.2 Agregamos el árbol retornado por la llamada recursiva al árbol generado en el punto 3.\n",
        "\n",
        "5. En el caso de que el atributo seleccionado sea continuo:\n",
        "\n",
        "  5.1 Creamos un objeto de tipo G02TreeContNode con el valor seleccionado para la generación de los intervalos (Ver Sesión Selección del \"mejor\" atributo en el paso recursivo) y el atributo IsFirstSet en True, que indica te estamos creando la rama con los valores menores o iguales.\n",
        "  5.2 Obtenemos los ejemplos con el valor del atributo menor o igual al de nuestra partición. Y ejecutamos la llamada recursiva con esos ejemplos y maxLevels-1\n",
        "  5.3 Agregamos el resultado de esa llamada al árbol generado en el punto 3.\n",
        "  5.4 repetimos los pasos 5.1, 5.2 y 5.3 pero teniendo en cuenta los ejemplos con los valores mayores al de nuestra partición.\n",
        "\n",
        "6. Retornamos el árbol generado en el punto 3, con ya todos sus nodos internos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbrKzU2ZSjpS"
      },
      "source": [
        "## 2.3 Evaluación\n",
        "Para la evaluación de los resultados, se utilizaron las métricas propuestas en la letra del laboratorio, utilizando el paquete Sklearn.metrics y las funciones: acc, precisión, recall y f1. También para la matriz de confusión utilizamos el paquete SkLear.metrics y confusion_matrix.\n",
        "\n",
        "Para la separación de los conjuntos de entrenamiento y evaluación, también utilizamos la librería sklearn y la función train_test_split con una proporción de 80%-20% y random_state=42 para que los resultados sean reproducibles. \n",
        "\n",
        "En nuestra evaluación lo que hicimos fue a grandes rasgos:\n",
        "1. Pre procesar los datos, convirtiendo los valores discretos a reales\n",
        "2. Eliminamos el atributo \"Id\", ya que nos generaría un sobreajuste y no proporciona ninguna información útil en este contexto.\n",
        "3. Separamos el conjunto de entrenamiento y el de evaluación en un 80% - 20%\n",
        "4. Creamos nuestro árbol de decisión y evaluamos las métricas\n",
        "5. Arreglamos los datos modificando su distribución haciendo oversampler.\n",
        "6. Ejecutamos nuevamente los pasos 3 y 4 pero con los ejemplos balanceados.\n",
        "\n",
        "Tal como lo propone la letra del laboratorio, hacemos una comparación con los resultados del algoritmo de sklearn DecisionTreeClassifier, de la misma manera que con nuestro algoritmo. No exactamente con los mismos ejemplos, pero si la misma metodología detallada anteriormente.\n",
        "\n",
        "Para la visualización más adecuada del árbol de decisión resultante de nuestro algoritmo, creamos una función llamada \"SaveId3Tree\" que guarda nuestro árbol formateado en texto plano para poder analizar mejor lo que fue generado. En la carpeta de nuestra solución tenemos algunos ejemplos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhah7KAlM1E-"
      },
      "source": [
        "## 3. Experimentación\n",
        "Para la experimentación, vamos a realizar los mismos pasos especificados en la sesión 2.3.\n",
        "\n",
        "### 3.1 Carga de DataSet \n",
        "Lo primero que hacemos es levantar los datos del DataSet usando panda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "RNEPgf3zM1E_",
        "outputId": "ffc359a5-1283-4808-f730-49caf396ca98"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics as stat\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import RandomOverSampler as oversampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import f1_score as f1\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "from sklearn.metrics import precision_score as precision\n",
        "from sklearn.metrics import recall_score as recall\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "\n",
        "#Carga de datos y prueba con sicklearn:\n",
        "df = pd.read_csv(\".\\healthcare-dataset-stroke-data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Pre Procesamiento de los datos\n",
        "Luego del análisis de los datos, tenemos que los siguientes atributos son de tipo texto, pero con valores discretos: ever_married, gender,work_type, Residence_type y smoking_status. Entonces procedemos a su reemplazo por valores discretos reales. También, como fue descrito anteriormente, eliminamos del conjunto de datos al atributo \"id\", ya que sería perjudicial para nuestro algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6zfXoJwYM1FE"
      },
      "outputs": [],
      "source": [
        "#modificamos los enumerados a valores reales discretos\n",
        "df['ever_married'] = df['ever_married'].replace(['Yes', 'No'], [1,0])\n",
        "df['gender'] = df['gender'].replace(['Male', 'Female', 'Other'], [0,1,2])\n",
        "df['work_type'] = df['work_type'].replace(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'], [0,1,2,3,4])\n",
        "df['Residence_type'] = df['Residence_type'].replace(['Urban', 'Rural'], [1,0])\n",
        "df['smoking_status'] = df['smoking_status'].replace(['formerly smoked', 'never smoked', 'smokes', 'Unknown'], [0,1,2,3])\n",
        "del df[\"id\"] #el id no puede ir ya que hace sobreajuste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Separación de conjuntos y reemplazo valores nulos\n",
        "Creamos una copia del DataFrame y hacemos una separación de los conjuntos de entrenamiento y conjunto de validación en un 80% - 20% con un random_state =42. Luego de esta separación, como parte del procesamiento reemplazamos los valores n/a del atributo \"bmi\" que es el único al que tenemos que procesar en este contexto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VxP_cVoIM1FH"
      },
      "outputs": [],
      "source": [
        "dfGlobal = df.copy()\n",
        "#1022 test size porque es el 20%, 5110 datos en total\n",
        "df_train, df_test = train_test_split(dfGlobal, test_size=0.2, random_state=42)\n",
        "\n",
        "#en el conjunto de entrenamiento, cambiamos los valores null por la media\n",
        "media = df_train['bmi'].median()\n",
        "df_train['bmi'] = df_train['bmi'].replace(['N/A'], [media])\n",
        "df_train['bmi'] = df_train['bmi'].fillna(media)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Inicio de pruebas de nuestro algoritmo\n",
        "\n",
        "Primero importamos nuestra lógica del clasificador y especificamos una función para la impresión de métricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cOpp1if8M1FC"
      },
      "outputs": [],
      "source": [
        "import g02_l2_core\n",
        "#funcion para imprimir las metricas\n",
        "def PrintMetrics(Y_test, predict):\n",
        "    print(\"Accuracy -> \"+str(acc (Y_test, predict)))\n",
        "    print(\"Precision -> \"+str(precision (Y_test, predict)))\n",
        "    print(\"Recall -> \"+str(recall (Y_test, predict)))\n",
        "    print(\"F1 -> \"+str(f1 (Y_test, predict)))\n",
        "    print(\"Matriz de Confusión:\")\n",
        "    tn, fp, fn, tp = confusion_matrix(Y_test, predict).ravel()\n",
        "    print(\"      1        0\")\n",
        "    print(\" 1    {:<8} {:<8} \".format(tp, fp))\n",
        "    print(\" 0    {:<8} {:<8} \".format(fn, tn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.4.1 Prueba con 7 niveles\n",
        "La primera prueba con un árbol de 7 niveles y datos desbalanceados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rS40IVoxM1FI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy -> 0.9393346379647749\n",
            "Precision -> 0.0\n",
            "Recall -> 0.0\n",
            "F1 -> 0.0\n",
            "Matriz de Confusión:\n",
            "      1        0\n",
            " 1    0        0        \n",
            " 0    62       960      \n"
          ]
        }
      ],
      "source": [
        "#Prueba con 7 niveles\n",
        "maxTreeLevels = 4\n",
        "ID3_tree = g02_l2_core.ID3_DecisionTree(df_train, maxTreeLevels)\n",
        "g02_l2_core.SaveId3Tree(f\"G02_ID3_tree_{maxTreeLevels}.txt\", ID3_tree)\n",
        "\n",
        "predict = g02_l2_core.TestID3Tree(df_test, ID3_tree)\n",
        "PrintMetrics(df_test['stroke'].values, predict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que en esta prueba el árbol tiene una generalización muy grande, lo que ocasiona que retorne en todos los casos false, ya que en su entrenamiento no llego a procesar datos con resultado verdaderos (ver G02_ID3_tree_7.txt).\n",
        "Ya con esta prueba podemos ver la poca utilidad de la métrica Accurancy en este contexto, ya que nos retorna alrededor de un 93% de acierto, pero esto se debe a la mala distribución de los datos que ocasiona que la gran mayoría de los ejemplos son falsos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.4.2 Prueba con más niveles\n",
        "La Segunda prueba es con un árbol de 10 niveles y otra con libertad en la cantidad de niveles, en ambos casos con datos aun desbalanceados (G02_ID3_tree_10.txt y G02_ID3_tree_Full.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cqcJKs_rM1FJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy -> 0.9315068493150684\n",
            "Precision -> 0.21428571428571427\n",
            "Recall -> 0.04838709677419355\n",
            "F1 -> 0.07894736842105263\n",
            "Matriz de Confusión:\n",
            "      1        0\n",
            " 1    3        11       \n",
            " 0    59       949      \n"
          ]
        }
      ],
      "source": [
        "#Prueba con 10 niveles\n",
        "maxTreeLevels = 10\n",
        "ID3_tree = g02_l2_core.ID3_DecisionTree(df_train, maxTreeLevels)\n",
        "g02_l2_core.SaveId3Tree(f\"G02_ID3_tree_{maxTreeLevels}.txt\", ID3_tree)\n",
        "\n",
        "predict = g02_l2_core.TestID3Tree(df_test, ID3_tree)\n",
        "PrintMetrics(df_test['stroke'].values, predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZJhkXXpEM1FK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy -> 0.9315068493150684\n",
            "Precision -> 0.21428571428571427\n",
            "Recall -> 0.04838709677419355\n",
            "F1 -> 0.07894736842105263\n",
            "Matriz de Confusión:\n",
            "      1        0\n",
            " 1    3        11       \n",
            " 0    59       949      \n"
          ]
        }
      ],
      "source": [
        "#Prueba con el maximo de niveles\n",
        "ID3_tree = g02_l2_core.ID3_DecisionTree(df_train, None)\n",
        "g02_l2_core.SaveId3Tree(f\"G02_ID3_tree_Full.txt\", ID3_tree)\n",
        "\n",
        "predict = g02_l2_core.TestID3Tree(df_test, ID3_tree)\n",
        "PrintMetrics(df_test['stroke'].values, predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En estas primeras pruebas, se nota mucho la importancia de la distribución en los datos, ya que las métricas arrojan datos considerados por nosotros como malos, basta analizar las métricas Recall y Precisión que no pasan de un 20%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zv8r4iaM1FL"
      },
      "source": [
        "#### 3.4.2 Distribución de los datos\n",
        "Como surge de las pruebas anteriores, los datos tienen una distribución muy despareja con respecto a los retornos en el atributo Stroke.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "dfDistribuida = df.copy()\n",
        "sns.countplot(data = dfDistribuida, x=\"stroke\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación vamos a solucionar la mala distribución usando overSampler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7x5knxvQM1FN"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQh0lEQVR4nO3dfayedX3H8fcHKjjxgSIdg5atTDsdxol4Bjj9Y0IGBZ0wIwano7Im3Ra2SGa24bLIBpJodHPqJkkjSHGbyHQO5ozYVHxYosCpPAhljE5FWsFWWlAk6Irf/XF+dTflnP4O7FznnHLer+TOfV3f63dd9/dOTs4n1+OdqkKSpL3Zb64bkCTNf4aFJKnLsJAkdRkWkqQuw0KS1LVorhsYwqGHHlrLly+f6zYkaZ+ycePG71XVksmWPSXDYvny5YyPj891G5K0T0ly91TLBj0MleRbSb6e5OYk4612SJL1Se5q74tbPUk+kGRzkluTHDuynVVt/F1JVg3ZsyTp8WbjnMWrquqYqhpr8+cDG6pqBbChzQOcCqxorzXAJTARLsAFwPHAccAFuwNGkjQ75uIE9+nAuja9DjhjpH5FTfgqcHCSw4FTgPVVtaOqdgLrgZWz3LMkLWhDh0UBn0uyMcmaVjusqu5t0/cBh7XppcA9I+tuabWp6o+RZE2S8STj27dvn8nvIEkL3tAnuF9ZVVuT/CywPsl/ji6sqkoyIw+nqqq1wFqAsbExH3glSTNo0D2Lqtra3rcBn2LinMN32+El2vu2NnwrcOTI6stabaq6JGmWDBYWSQ5K8qzd08DJwG3ANcDuK5pWAVe36WuAs9tVUScAD7bDVdcCJydZ3E5sn9xqkqRZMuRhqMOATyXZ/Tn/VFWfTXIjcFWS1cDdwBva+M8ApwGbgYeBcwCqakeSi4Ab27gLq2rHgH1LkvaQp+LvWYyNjZU35UnSE5Nk48htDo/xlLyDeya87E+umOsWNA9tfM/Zc90C377wxXPdguahn3/H1wfdvg8SlCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlr8LBIsn+Sm5J8us0fleT6JJuTfDzJAa1+YJvf3JYvH9nG21v9ziSnDN2zJOmxZmPP4q3AHSPz7wbeV1XPB3YCq1t9NbCz1d/XxpHkaOAs4EXASuBDSfafhb4lSc2gYZFkGfBq4MNtPsCJwCfakHXAGW369DZPW35SG386cGVV/aiqvglsBo4bsm9J0mMNvWfxt8CfAj9p888FHqiqXW1+C7C0TS8F7gFoyx9s439an2Sdn0qyJsl4kvHt27fP8NeQpIVtsLBI8hpgW1VtHOozRlXV2qoaq6qxJUuWzMZHStKCsWjAbb8CeG2S04CnA88G3g8cnGRR23tYBmxt47cCRwJbkiwCngPcP1LfbXQdSdIsGGzPoqreXlXLqmo5EyeoP19VbwKuA17fhq0Crm7T17R52vLPV1W1+lntaqmjgBXADUP1LUl6vCH3LKbyZ8CVSd4J3ARc2uqXAh9NshnYwUTAUFW3J7kK2ATsAs6tqkdnv21JWrhmJSyq6gvAF9r0N5jkaqaqegQ4c4r1LwYuHq5DSdLeeAe3JKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUNFhZJnp7khiS3JLk9yV+1+lFJrk+yOcnHkxzQ6ge2+c1t+fKRbb291e9McspQPUuSJjfknsWPgBOr6iXAMcDKJCcA7wbeV1XPB3YCq9v41cDOVn9fG0eSo4GzgBcBK4EPJdl/wL4lSXsYLCxqwkNt9mntVcCJwCdafR1wRps+vc3Tlp+UJK1+ZVX9qKq+CWwGjhuqb0nS4w16ziLJ/kluBrYB64H/Bh6oql1tyBZgaZteCtwD0JY/CDx3tD7JOqOftSbJeJLx7du3D/BtJGnhGjQsqurRqjoGWMbE3sALB/ystVU1VlVjS5YsGepjJGlBmpWroarqAeA64OXAwUkWtUXLgK1teitwJEBb/hzg/tH6JOtIkmbBkFdDLUlycJv+GeA3gDuYCI3Xt2GrgKvb9DVtnrb881VVrX5Wu1rqKGAFcMNQfUuSHm9Rf8iTdjiwrl25tB9wVVV9Oskm4Mok7wRuAi5t4y8FPppkM7CDiSugqKrbk1wFbAJ2AedW1aMD9i1J2sNgYVFVtwIvnaT+DSa5mqmqHgHOnGJbFwMXz3SPkqTp8Q5uSVKXYSFJ6ppWWCTZMJ2aJOmpaa/nLJI8HXgGcGiSxUDaomczyY1xkqSnpt4J7t8DzgOOADbyf2HxfeDvhmtLkjSf7DUsqur9wPuT/FFVfXCWepIkzTPTunS2qj6Y5NeA5aPrVNUVA/UlSZpHphUWST4KPA+4Gdh9Q1wBhoUkLQDTvSlvDDi6PX5DkrTATPc+i9uAnxuyEUnS/DXdPYtDgU1JbmDiF/AAqKrXDtKVJGlemW5Y/OWQTUiS5rfpXg31xaEbkSTNX9O9GuoHTFz9BHAAE7+n/cOqevZQjUmS5o/p7lk8a/d0kgCnAycM1ZQkaX55wk+drQn/Cpwy8+1Ikuaj6R6Get3I7H5M3HfxyCAdSZLmneleDfWbI9O7gG8xcShKkrQATPecxTlDNyJJmr+m++NHy5J8Ksm29vpkkmVDNydJmh+me4L7I8A1TPyuxRHAv7WaJGkBmG5YLKmqj1TVrva6HFgyYF+SpHlkumFxf5I3J9m/vd4M3D9kY5Kk+WO6YfG7wBuA+4B7gdcDbxmoJ0nSPDPdS2cvBFZV1U6AJIcA72UiRCRJT3HT3bP4ld1BAVBVO4CXDtOSJGm+mW5Y7Jdk8e6Ztmcx3b0SSdI+brr/8P8a+EqSf27zZwIXD9OSJGm+me4d3FckGQdObKXXVdWm4dqSJM0n0z6U1MLBgJCkBegJP6JckrTwGBaSpC7DQpLUNVhYJDkyyXVJNiW5PclbW/2QJOuT3NXeF7d6knwgyeYktyY5dmRbq9r4u5KsGqpnSdLkhtyz2AW8raqOZuL3us9NcjRwPrChqlYAG9o8wKnAivZaA1wCP72n4wLgeOA44ILRez4kScMbLCyq6t6q+lqb/gFwB7CUiV/YW9eGrQPOaNOnA1e03/j+KnBwksOZ+K3v9VW1o91Fvh5YOVTfkqTHm5VzFkmWM/F4kOuBw6rq3rboPuCwNr0UuGdktS2tNlVdkjRLBg+LJM8EPgmcV1XfH11WVQXUDH3OmiTjSca3b98+E5uUJDWDhkWSpzERFP9YVf/Syt9th5do79tafStw5Mjqy1ptqvpjVNXaqhqrqrElS/xdJkmaSUNeDRXgUuCOqvqbkUXXALuvaFoFXD1SP7tdFXUC8GA7XHUtcHKSxe3E9smtJkmaJUM+OfYVwO8AX09yc6v9OfAu4Kokq4G7mfhRJYDPAKcBm4GHgXNg4nHoSS4CbmzjLmyPSJckzZLBwqKq/gPIFItPmmR8AedOsa3LgMtmrjtJ0hPhHdySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1DVYWCS5LMm2JLeN1A5Jsj7JXe19casnyQeSbE5ya5JjR9ZZ1cbflWTVUP1KkqY25J7F5cDKPWrnAxuqagWwoc0DnAqsaK81wCUwES7ABcDxwHHABbsDRpI0ewYLi6r6ErBjj/LpwLo2vQ44Y6R+RU34KnBwksOBU4D1VbWjqnYC63l8AEmSBjbb5ywOq6p72/R9wGFteilwz8i4La02Vf1xkqxJMp5kfPv27TPbtSQtcHN2gruqCqgZ3N7aqhqrqrElS5bM1GYlScx+WHy3HV6ivW9r9a3AkSPjlrXaVHVJ0iya7bC4Bth9RdMq4OqR+tntqqgTgAfb4aprgZOTLG4ntk9uNUnSLFo01IaTfAz4deDQJFuYuKrpXcBVSVYDdwNvaMM/A5wGbAYeBs4BqKodSS4CbmzjLqyqPU+aS5IGNlhYVNUbp1h00iRjCzh3iu1cBlw2g61Jkp4g7+CWJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK59JiySrExyZ5LNSc6f634kaSHZJ8Iiyf7A3wOnAkcDb0xy9Nx2JUkLxz4RFsBxwOaq+kZV/Ri4Ejh9jnuSpAVj0Vw3ME1LgXtG5rcAx48OSLIGWNNmH0py5yz1thAcCnxvrpuYD/LeVXPdgh7Lv83dLshMbOUXplqwr4RFV1WtBdbOdR9PRUnGq2psrvuQ9uTf5uzZVw5DbQWOHJlf1mqSpFmwr4TFjcCKJEclOQA4C7hmjnuSpAVjnzgMVVW7kvwhcC2wP3BZVd0+x20tJB7e03zl3+YsSVXNdQ+SpHluXzkMJUmaQ4aFJKnLsNBe+ZgVzUdJLkuyLcltc93LQmFYaEo+ZkXz2OXAyrluYiExLLQ3PmZF81JVfQnYMdd9LCSGhfZmssesLJ2jXiTNIcNCktRlWGhvfMyKJMCw0N75mBVJgGGhvaiqXcDux6zcAVzlY1Y0HyT5GPAV4AVJtiRZPdc9PdX5uA9JUpd7FpKkLsNCktRlWEiSugwLSVKXYSFJ6jIspBmS5Lwkz3iC6yz3yanaFxgW0sw5D5g0LNoTfKV9lmEhPQlJDkry70luSXJbkguAI4DrklzXxjyU5K+T3AK8PMkft7G3JTlvkm3+YpKbkvxqkucl+WySjUm+nOSFs/sNpcdaNNcNSPuolcB3qurVAEmeA5wDvKqqvtfGHARcX1VvS/Kytvx4IMD1Sb4I7Gzrv4CJR8C/papuSbIB+P2quivJ8cCHgBNn8ftJj+Ed3NKTkOSXgM8BHwc+XVVfTvItYGx3WCTZBRxYVY8meSvw3Kp6R1t2EbCdiWdtXc9EaLyuqjYleWZbdufIRx5YVb88S19Pehz3LKQnoar+K8mxwGnAO9uewJ4eqapHp7G5B4FvA68ENjFxePiBqjpmpvqV/r88ZyE9CUmOAB6uqn8A3gMcC/wAeNYUq3wZOCPJM5IcBPxWqwH8uM2fneS3q+r7wDeTnNk+K0leMuDXkbrcs5CenBcD70nyE+B/gD8AXg58Nsl3qupVo4Or6mtJLgduaKUPV9VNSZa35T9M8hpgfZKHgDcBlyT5C+BpTJzPuGUWvpc0Kc9ZSJK6PAwlSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6/hdJBkL0kn95uQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "#distribucion del stroke\n",
        "ros = oversampler(random_state=42)\n",
        "X = dfDistribuida[[\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\",\n",
        "        \"avg_glucose_level\", \"bmi\", \"smoking_status\"]]\n",
        "Y = dfDistribuida.stroke\n",
        "X, Y = ros.fit_resample(X,Y)\n",
        "dfDistribuida = X\n",
        "dfDistribuida[\"stroke\"] = Y\n",
        "\n",
        "sns.countplot(data = dfDistribuida, x=\"stroke\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.4.3 Distribución de los datos\n",
        "Una vez mejorada la distribución de los datos con respecto al atributo \"stroke\" procedemos a testear nuevamente nuestro árbol de decisión, para esto debemos participar nuevamente los conjuntos y reemplazar los valores nulos en \"bmi\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4UxQuotBM1FN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy -> 0.8344473007712082\n",
            "Precision -> 0.78125\n",
            "Recall -> 0.9278350515463918\n",
            "F1 -> 0.8482563619227144\n",
            "Matriz de Confusión:\n",
            "      1        0\n",
            " 1    900      252      \n",
            " 0    70       723      \n"
          ]
        }
      ],
      "source": [
        "df_train, df_test = train_test_split(dfDistribuida, test_size=0.2, random_state=42)\n",
        "\n",
        "#en el conjunto de entrenamiento, cambiamos los valores null por la media\n",
        "media = df_train['bmi'].median()\n",
        "df_train['bmi'] = df_train['bmi'].replace(['N/A'], [media])\n",
        "df_train['bmi'] = df_train['bmi'].fillna(media)\n",
        "\n",
        "#Prueba con maximo niveles\n",
        "ID3_tree = g02_l2_core.ID3_DecisionTree(df_train, None)\n",
        "g02_l2_core.SaveId3Tree(f\"G02_ID3_tree_{maxTreeLevels}.txt\", ID3_tree)\n",
        "\n",
        "predict = g02_l2_core.TestID3Tree(df_test, ID3_tree)\n",
        "PrintMetrics(df_test['stroke'].values, predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Claramente, las métricas mejoraron mucho llegando a valores de Precision=78%, recall=92% y f1=84%. En la matriz de confusión podemos observar que estamos penalizando mucho con los Falsos positivos y pensamos que se debe al oversampler utilizado. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU-XNAy1M1FO"
      },
      "source": [
        "### 3.5 Comparación con Sklearn\n",
        "\n",
        "Como parte del análisis de nuestro algoritmo surge la necesidad de comparar nuestras métricas con las de otro algoritmo, en este caso sklean y su \"DecisionTreeClassifier\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.5.1 Prueba con datos desbalanceados\n",
        "La primera prueba que queremos hacer es con los mismos datos desbalanceados que probamos en nuestro algoritmo, por lo que probamos con los datos originales y haciendo una separación en conjuntos 80% - 20%.\n",
        "Una diferencia con nuestro algoritmo es que sklear no soporta testear datos con el \"bmi\" en \"N/A\" por lo que para esta prueba decidimos reemplazar esos valores por la media."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nsxHz2loM1FP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy -> 0.898238747553816\n",
            "Precision -> 0.125\n",
            "Recall -> 0.11290322580645161\n",
            "F1 -> 0.11864406779661016\n",
            "Matriz de Confusión:\n",
            "      1        0\n",
            " 1    7        49       \n",
            " 0    55       911      \n"
          ]
        }
      ],
      "source": [
        "#prueba con el algoritmo de sklearn\n",
        "dfSkLearn = df.copy()\n",
        "#sklearn no soporta nan, entonces como son pocos, optamos por ponerles tambien la media para estas pruebas\n",
        "media = dfSkLearn['bmi'].median()\n",
        "dfSkLearn['bmi'] = dfSkLearn['bmi'].replace(['N/A'], [media])\n",
        "dfSkLearn['bmi'] = dfSkLearn['bmi'].fillna(media)\n",
        "\n",
        "X = dfSkLearn[[\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\",\n",
        "        \"avg_glucose_level\", \"bmi\", \"smoking_status\"]]\n",
        "Y = dfSkLearn.stroke\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt_clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "dt_clf = dt_clf.fit(X_train, Y_train)\n",
        "Y_pred = dt_clf.predict(X_test)\n",
        "\n",
        "PrintMetrics(Y_test, Y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuevamente, vemos métricas muy parecidas con nuestra solución, una Accurrency alta (89%) pero valores de Precision y Recall muy bajos.\n",
        "<table>\n",
        "<tr><th></th> <th>ID3 G02</th> <th>Sklearn</th></tr>\n",
        "<tr><td>Accuracy</td> <td> 0.9315068493150684</td> <td>0.898238747553816</td></tr>\n",
        "<tr><td>Precision</td> <td>0.21428571428571427</td> <td>0.125</td></tr>\n",
        "<tr><td>Recall</td> <td>0.04838709677419355</td> <td>0.11290322580645161</td></tr>\n",
        "<tr><td>F1</td> <td>0.07894736842105263</td> <td>0.11864406779661016</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.5.2 Prueba con datos balanceados\n",
        "La segunda prueba es con sklearn pero con la mejora en la distribución de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nsxHz2loM1FP"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy -> 0.9840616966580977\n",
            "Precision -> 0.9690309690309691\n",
            "Recall -> 1.0\n",
            "F1 -> 0.9842719431760528\n",
            "Matriz de Confusión:\n",
            "      1        0\n",
            " 1    970      31       \n",
            " 0    0        944      \n"
          ]
        }
      ],
      "source": [
        "#prueba con el algoritmo de sklearn\n",
        "dfSkLearnDistribuida = df.copy()\n",
        "\n",
        "ros = oversampler(random_state=42)\n",
        "X, Y = ros.fit_resample(X,Y)\n",
        "dfSkLearnDistribuida = X\n",
        "dfSkLearnDistribuida[\"stroke\"] = Y\n",
        "sns.countplot(data = dfSkLearnDistribuida, x=\"stroke\")\n",
        "plt.show()\n",
        "\n",
        "#sklearn no soporta nan, entonces como son pocos, optamos por ponerles tambien la media para estas pruebas\n",
        "media = dfSkLearnDistribuida['bmi'].median()\n",
        "dfSkLearnDistribuida['bmi'] = dfSkLearnDistribuida['bmi'].replace(['N/A'], [media])\n",
        "dfSkLearnDistribuida['bmi'] = dfSkLearnDistribuida['bmi'].fillna(media)\n",
        "\n",
        "X = dfSkLearnDistribuida[[\"gender\", \"age\", \"hypertension\", \"heart_disease\", \"ever_married\", \"work_type\", \"Residence_type\",\n",
        "        \"avg_glucose_level\", \"bmi\", \"smoking_status\"]]\n",
        "Y = dfSkLearnDistribuida.stroke\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt_clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "dt_clf = dt_clf.fit(X_train, Y_train)\n",
        "Y_pred = dt_clf.predict(X_test)\n",
        "PrintMetrics(Y_test, Y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como era de esperarse, las métricas mejoran, teniendo si valores mucho mejores que los de nuestra solución. Otro punto a destacar es que la métrica Recall está en 1, dando a sospechar de un posible sobreajuste, lo que indicaría que podría no ser tan buena esa solución retornada por sklearn.\n",
        "<table>\n",
        "<tr><th></th> <th>ID3 G02</th> <th>Sklearn</th></tr>\n",
        "<tr><td>Accuracy</td> <td> 0.8344473007712082</td> <td>0.9840616966580977</td></tr>\n",
        "<tr><td>Precision</td> <td>0.78125</td> <td>0.9690309690309691</td></tr>\n",
        "<tr><td>Recall</td> <td>0.9278350515463918</td> <td>1.0</td></tr>\n",
        "<tr><td>F1</td> <td>0.8482563619227144</td> <td>0.9842719431760528</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-lTVnYFM1FS"
      },
      "source": [
        "## 4. Conclusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJiTHUjiM1FT"
      },
      "source": [
        "Se llegó a una implementación del algoritmo ID3 que creemos fue buena, con tiempo de ejecución buenos y métricas que si bien son peores que sklearn, creemos que con mejoras sería posible acercanos un poco. \n",
        "Como es de esperarse para los árboles de decisión se requiere de un gran trabajo de preprocesamiento en los datos, ya que la creación del árbol va a depender mucho de la cantidad de ejemplos y su distribución.\n",
        "\n",
        "Creemos que es posible una mejora en las métricas probando otras formas de ajustar la distribución de los ejemplos. También algo muy importante sería lograr obtener una cantidad más de casos positivos para el entrenamiento."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UtPsdk3bSQVp",
        "z0Jo0tgmO9je",
        "hZvL7jJGRZCx",
        "FbR2I0N-TKJe",
        "QwajseAuQZq4",
        "DEDxEYc_Sxsi",
        "z8ON-2Dqpocn",
        "Ds0j_PqaS3G1",
        "9fRX080oShOy",
        "kbrKzU2ZSjpS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b91e75ecf58b5a6634cf00da16aa84c65e4ecc8652670cacf5a34b50a804f10a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
